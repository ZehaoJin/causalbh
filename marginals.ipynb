{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from bge_score_jax import BGe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all possible DAGs for n nodes, generated by \"generate_all_dags.py\"\n",
    "dags_compressed = np.load('your_folder/dags_7.npy')\n",
    "# verify the length a bit, should match to 1, 3, 25, 543, 29281, 3781503, 1138779265, 783702329343 for n nodes\n",
    "dags_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in your data\n",
    "dfs = pd.read_csv('your_data.csv')\n",
    "dfs = dfs.apply(lambda col: ( col - col.mean() ) / col.std(), axis=0)  # Standardize data\n",
    "observations = np.asarray(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a few functions\n",
    "def compute_exact_posterior(dags_compressed, observations, batch_size=1, verbose=True):\n",
    "    num_variables = observations.shape[1]\n",
    "    model = BGe(num_variables=num_variables)\n",
    "\n",
    "    @jax.jit\n",
    "    def log_prob(observations, adjacencies_compressed):\n",
    "        adjacencies = jnp.unpackbits(adjacencies_compressed, axis=1, count=num_variables ** 2)\n",
    "        adjacencies = adjacencies.reshape(-1, num_variables, num_variables)\n",
    "\n",
    "        v_log_prob = jax.vmap(model.log_prob, in_axes=(None, 0))\n",
    "        log_probs = v_log_prob(observations, adjacencies)\n",
    "        return jnp.sum(log_probs, axis=1)\n",
    "\n",
    "    num_dags = dags_compressed.shape[0]\n",
    "    log_probs = np.zeros((num_dags,), dtype=np.float32)\n",
    "    for i in trange(0, num_dags, batch_size, disable=(not verbose)):\n",
    "        # Get a batch of (compressed) DAGs\n",
    "        batch_compressed = dags_compressed[i:i + batch_size]\n",
    "\n",
    "        # Compute the BGe scores\n",
    "        log_probs[i:i + batch_size] = log_prob(observations, batch_compressed)\n",
    "\n",
    "    # Normalize the log-marginal probabilities\n",
    "    log_probs = log_probs - logsumexp(log_probs)\n",
    "    return log_probs\n",
    "\n",
    "def edge_log_marginal(dags_compressed, log_joint, num_variables, batch_size=1, verbose=True):\n",
    "    @jax.jit\n",
    "    def marginalize(log_probs, adjacencies_compressed):\n",
    "        adjacencies = jnp.unpackbits(adjacencies_compressed, axis=1, count=num_variables ** 2)\n",
    "        log_probs = jnp.where(adjacencies == 1, log_probs[:, None], -jnp.inf)\n",
    "        return jax.nn.logsumexp(log_probs, axis=0)\n",
    "\n",
    "    num_dags = dags_compressed.shape[0]\n",
    "    log_marginal = []\n",
    "    for i in trange(0, num_dags, batch_size, disable=(not verbose)):\n",
    "        # Get a batch of data\n",
    "        batch_compressed = dags_compressed[i:i + batch_size]\n",
    "        log_probs = log_joint[i:i + batch_size]\n",
    "\n",
    "        log_marginal.append(marginalize(log_probs, batch_compressed))\n",
    "\n",
    "    log_marginal = np.stack(log_marginal, axis=0)\n",
    "    log_marginal = logsumexp(log_marginal, axis=0)\n",
    "    return log_marginal.reshape(num_variables, num_variables)\n",
    "\n",
    "def get_transitive_closure(adjacency):\n",
    "    # Warshall's algorithm\n",
    "    def scan_fun(closure, i):\n",
    "        outer_product = jnp.outer(closure[:, i], closure[i])\n",
    "        return (jnp.logical_or(closure, outer_product), None)\n",
    "    \n",
    "    adjacency = adjacency.astype(jnp.bool_)\n",
    "    arange = jnp.arange(adjacency.shape[0])\n",
    "    closure, _ = jax.lax.scan(scan_fun, adjacency, arange)\n",
    "\n",
    "    return closure\n",
    "\n",
    "def path_log_marginal(dags_compressed, log_joint, num_variables, batch_size=1, verbose=True):\n",
    "    @jax.jit\n",
    "    def marginalize(log_probs, adjacencies_compressed):\n",
    "        adjacencies = jnp.unpackbits(adjacencies_compressed, axis=1, count=num_variables ** 2)\n",
    "        adjacencies = adjacencies.reshape(-1, num_variables, num_variables)\n",
    "        closures = jax.vmap(get_transitive_closure)(adjacencies)\n",
    "        log_probs = jnp.where(closures, log_probs[:, None, None], -jnp.inf)\n",
    "        return jax.nn.logsumexp(log_probs, axis=0)\n",
    "\n",
    "    num_dags = dags_compressed.shape[0]\n",
    "    log_marginal = []\n",
    "    for i in trange(0, num_dags, batch_size, disable=(not verbose)):\n",
    "        # Get a batch of data\n",
    "        batch_compressed = dags_compressed[i:i + batch_size]\n",
    "        log_probs = log_joint[i:i + batch_size]\n",
    "\n",
    "        log_marginal.append(marginalize(log_probs, batch_compressed))\n",
    "\n",
    "    log_marginal = np.stack(log_marginal, axis=0)\n",
    "    log_marginal = logsumexp(log_marginal, axis=0)\n",
    "    return log_marginal.reshape(num_variables, num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('your_output_folder/exact_posteriors')\n",
    "\n",
    "# compute exact posteriors\n",
    "log_joint = compute_exact_posterior(dags_compressed, observations, batch_size=2048)\n",
    "\n",
    "# compute edge marginals\n",
    "log_edge_marginals = edge_log_marginal(dags_compressed,\n",
    "    log_joint, observations.shape[1], batch_size=4096)\n",
    "\n",
    "with open(root / f'log_joint.npy', 'wb') as f:\n",
    "    np.save(f, log_joint)\n",
    "\n",
    "with open(root / f'log_edge_marginal.npy', 'wb') as f:\n",
    "    np.save(f, log_edge_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot edge marginals\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "log_edge_marginal = np.load(root / f'log_edge_marginal.npy')\n",
    "edge_marginal = pd.DataFrame(np.exp(log_edge_marginal),\n",
    "    index=dfs.columns, columns=dfs.columns)\n",
    "\n",
    "sns.heatmap(edge_marginal, cmap='gray',\n",
    "            annot=edge_marginal, fmt='.2f', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute path marginals\n",
    "log_joint = np.load(root / f'log_joint.npy')\n",
    "log_path_marginals = path_log_marginal(dags_compressed,\n",
    "    log_joint, observations.shape[1], batch_size=1024)\n",
    "\n",
    "with open(root / f'log_path_marginal.npy', 'wb') as f:\n",
    "    np.save(f, log_path_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot path marginals\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "log_path_marginal = np.load(root / f'log_path_marginal.npy')\n",
    "path_marginal = pd.DataFrame(np.exp(log_path_marginal),\n",
    "    index=dfs.columns, columns=dfs.columns)\n",
    "\n",
    "sns.heatmap(path_marginal, cmap='gray',\n",
    "            annot=path_marginal, fmt='.2f', cbar=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
